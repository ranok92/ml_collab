{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import json\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_OMCS_file(filename, language='en', save_filename=None):\n",
    "    '''\n",
    "    Given the filename and the language retrieves the sentences from the\n",
    "    provided language and stores it in another file.\n",
    "    input:\n",
    "        filename : string containing the name of the file\n",
    "        language : string containing the name of the language\n",
    "                   to look for.\n",
    "    \n",
    "    output: List of sentences from the OMCS text file belonging \n",
    "            to that particular language.\n",
    "    '''\n",
    "    data_list_language = []\n",
    "    \n",
    "    assert os.path.isfile(filename), 'File does not exist!'\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "         data_list = f.readlines()\n",
    "   \n",
    "    for data_line in data_list:\n",
    "        try:\n",
    "            if data_line.split('\\t')[4]==language:\n",
    "                data_list_language.append(data_line.split('\\t')[1])\n",
    "        except:\n",
    "            print('Found a faulty sentence :', data_line)\n",
    "            \n",
    "    if save_filename:\n",
    "        \n",
    "        with open(save_filename, 'w') as fp:\n",
    "            json.dump(data_list_language, fp)\n",
    "            \n",
    "    return data_list_language\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a faulty sentence : 1531350\tUm(a) golfinho Ã© usado(a) para brinc\n",
      "\n",
      "Found a faulty sentence : 1194903\tSome people like to check their e-mail first thing in the morning.\n",
      "\n",
      "Found a faulty sentence : 1194907\tPeople take showers in the morning.\n",
      "\n",
      "Found a faulty sentence : 1194921\tPeople eat cereal for breakfast.\n",
      "\n",
      "Found a faulty sentence : 1194929\tPeople can travel from work to home on a bicycle.\n",
      "\n",
      "Found a faulty sentence : 1194960\tPaper clips hold sheets of paper together.\n",
      "\n",
      "Found a faulty sentence : 1044642\tThe statement \"Telescopes make things look larger.\" is true because Refracting telescopes use lenses to gather and bend\n",
      "\n",
      "Found a faulty sentence : (898159 rows)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_OMCS_file('./data/omcs-sentences-free.txt', save_filename='english_sentences.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_sentences.txt', 'r') as fp:\n",
    "    en_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes RB advmod causes VERB\n",
      "lightning NN nsubj causes VERB\n",
      "causes VBZ ROOT causes VERB\n",
      "electricity NN compound shortouts NOUN\n",
      "shortouts NNS dobj causes VERB\n"
     ]
    }
   ],
   "source": [
    "#printing token information using spacy\n",
    "sentence = en_data[121]\n",
    "tag_info = nlp(sentence)\n",
    "for token in tag_info:\n",
    "    print(token.text, token.tag_, token.dep_, token.head.text, token.head.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning  |  lightning  |  nsubj  |  causes\n",
      "electricity shortouts  |  shortouts  |  dobj  |  causes\n"
     ]
    }
   ],
   "source": [
    "#getting noun chunks using spacy\n",
    "doc = nlp(sentence)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, \" | \", chunk.root.text, \" | \", chunk.root.dep_, \" | \",\n",
    "            chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the  |  det  |  film  |  NOUN  |  []\n",
      "film  |  nsubj  |  had  |  AUX  |  ['the']\n",
      "had  |  ROOT  |  had  |  AUX  |  ['film', 'patents', '.']\n",
      "200  |  nummod  |  patents  |  NOUN  |  []\n",
      "patents  |  dobj  |  had  |  AUX  |  ['200']\n",
      ".  |  punct  |  had  |  AUX  |  []\n"
     ]
    }
   ],
   "source": [
    "#navigating the parse tree\n",
    "sentence = \"the film had 200 patents.\"\n",
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    print(token.text,\" | \",  token.dep_,\" | \",  token.head.text,\" | \",  token.head.pos_,\" | \", \n",
    "            [child.text for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for getting the entities and relations from the tutorial\n",
    "\n",
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "  ent1 = \"\"\n",
    "  ent2 = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "  prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "  prefix = \"\"\n",
    "  modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "  for tok in nlp(sent):\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "    if tok.dep_ != \"punct\":\n",
    "      # check: token is a compound word or not\n",
    "      if tok.dep_ == \"compound\":\n",
    "        prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "      if tok.dep_.endswith(\"mod\") == True:\n",
    "        modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "      if tok.dep_.find(\"subj\") == True:\n",
    "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "        prefix = \"\"\n",
    "        modifier = \"\"\n",
    "        prv_tok_dep = \"\"\n",
    "        prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "      if tok.dep_.find(\"obj\") == True:\n",
    "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "      prv_tok_dep = tok.dep_\n",
    "      prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "  return [ent1.strip(), ent2.strip()]\n",
    "\n",
    "\n",
    "def get_relation(sent):\n",
    "\n",
    "  doc = nlp(sent)\n",
    "\n",
    "  # Matcher class object \n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  #define the pattern \n",
    "  pattern = [{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "  matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "  matches = matcher(doc)\n",
    "  k = len(matches) - 1\n",
    "\n",
    "  span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "  return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my code for extracting entities and relations\n",
    "\n",
    "def extract_subject_object(sent):\n",
    "    doc = nlp(sent)\n",
    "    subject = []\n",
    "    obj = []\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.dep_.find(\"subj\") == True and len(subject) == 0:\n",
    "            for child in token.children:\n",
    "                if child.dep_ not in [\"det\", \"punct\", \"conj\", \"prep\"]:\n",
    "                    subject.append(child.text)\n",
    "            subject.append(token.text)\n",
    "        \n",
    "        if token.dep_.find(\"obj\") == True and len(obj) == 0:\n",
    "            for child in token.children:\n",
    "                if child.dep_ not in [\"det\", \"punct\", \"conj\", \"prep\"]:\n",
    "                    obj.append(child.text)\n",
    "            obj.append(token.text)\n",
    "    \n",
    "    subject_string = \"\"\n",
    "    for token in subject:\n",
    "        subject_string += token\n",
    "        subject_string += \" \"\n",
    "    sub_string = subject_string.strip()\n",
    "    \n",
    "    object_string = \"\"\n",
    "    for token in obj:\n",
    "        object_string += token\n",
    "        object_string += \" \"\n",
    "    obj_string = object_string.strip(\" \")\n",
    "    return (sub_string, obj_string)\n",
    "\n",
    "\n",
    "def extract_entities_from_clause(clause):\n",
    "    '''\n",
    "    Tring someway to traverse the tree from the root and try finding \n",
    "    relationships from there onwards\n",
    "    '''\n",
    "    doc = nlp(clause)\n",
    "    root_children = []\n",
    "    subject = []\n",
    "    object_entity = ''\n",
    "    subject_entity = ''\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.dep_.find(\"obj\") == True:\n",
    "            object_entity = get_subtree_excluding_subclause(token)\n",
    "            print(\" The object : \",get_subtree_excluding_subclause(token))\n",
    "\n",
    "        if token.dep_.find(\"subj\") == True:\n",
    "            subject_entity = get_subtree_excluding_subclause(token)\n",
    "            print(\" The subject :\", get_subtree_excluding_subclause(token))\n",
    "    \n",
    "    return subject_entity, object_entity\n",
    "\n",
    "\n",
    "def extract_relation_from_clause(clause):\n",
    "    '''\n",
    "    Given a clause (independent or dependent) returns the \n",
    "    possible relation (verb). The relation is calculated \n",
    "    by taking the verb and \n",
    "    \n",
    "    \n",
    "    input:\n",
    "        clause : a string containing a single clause\n",
    "    '''\n",
    "    doc = nlp(clause)\n",
    "    dep_list = ['ROOT']\n",
    "    for token in doc:\n",
    "        if token.dep_ in dep_list:\n",
    "            return token\n",
    "            \n",
    "def extract_entity_relation_tuples(sent):\n",
    "    '''\n",
    "    Given a sentence, returns a list of entity relation tuples\n",
    "    Entity relation tuples are extracted for each of the clauses\n",
    "    detected in the sentence.\n",
    "    input:\n",
    "        sent : A sentence in the form of a string.\n",
    "    \n",
    "    output:\n",
    "        \n",
    "        entity_rel_list : A list containing enitiy relations extracted from \n",
    "                          individual clause.\n",
    "                          of the form [((subj, obj), rel), (), ()]\n",
    "    '''\n",
    "    clause_list = extract_clauses(sent)\n",
    "    entity_rel_list = []\n",
    "    for clause in clause_list:\n",
    "        \n",
    "        subj, obj = extract_entities_from_clause(clause)\n",
    "        rel = extract_relation_from_clause(clause)\n",
    "        entity_rel_list.append(((subj, obj), rel))\n",
    "    \n",
    "    \n",
    "    return entity_rel_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my code for extracting entities and relations\n",
    "\n",
    "    \n",
    "def check_verb_subject_in_clause(clause_token_list):\n",
    "    '''\n",
    "    Given a clause/sentence checks if the sentence contains\n",
    "    a subject and a verb.\n",
    "    input:\n",
    "        clause : a string containing a sentence\n",
    "        \n",
    "    output:\n",
    "        contains : A boolean flag indicating the presence \n",
    "                   of a verb and a subject in the sentence.\n",
    "    '''\n",
    "    pos_list = [\"VERB\"]\n",
    "    dep_list = ['aux']\n",
    "    contains = False\n",
    "    contains_verb = False\n",
    "    contains_sub = False\n",
    "    for token in clause_token_list:\n",
    "        print(\"token : {} | pos : {} | dep : {}\".format(token.text, token.pos_, token.dep_))\n",
    "        if token.dep_.find(\"subj\") == True:\n",
    "            contains_sub = True\n",
    "        if token.pos_ in pos_list or token.dep_ in dep_list:\n",
    "            contains_verb = True\n",
    "        print(\"Contains verb : {}, contains sub : {}\".format(contains_verb, contains_sub))\n",
    "    if contains_verb and contains_sub:\n",
    "        contains = True\n",
    "    return contains\n",
    "    \n",
    "         \n",
    "def get_subtree_excluding_subclause2(root_token, token_subtree, clausal_list):\n",
    "    '''\n",
    "    Gets  the subtree excluding \"relevant\" subclause. To qualify\n",
    "    for a clause, the part of the sentence should contain a \n",
    "    subject and a verb\n",
    "    '''\n",
    "    subtree_wo_clause = []\n",
    "    subtree_wo_clause_string = \"\"\n",
    "    accessed_token_list = []\n",
    "    for token in token_subtree:\n",
    "        print(\"TOKEN :\", token.text)\n",
    "        if token not in accessed_token_list:\n",
    "            if token.dep_ in clausal_list:\n",
    "                print(\"Calling function using token :\", token.text)\n",
    "                pdb.set_trace()\n",
    "                token_list, subtree_string = get_subtree_excluding_subclause2(token.subtree, clausal_list)\n",
    "                for tok in token_list:\n",
    "                    accessed_token_list.append(tok)\n",
    "                if len(token_list) == 0: #invalid subclause\n",
    "                    subtree_wo_clause.append(token)\n",
    "            else:\n",
    "                subtree_wo_clause.append(token)\n",
    "    \n",
    "    #once the entire token_subtree is scanned and collected for\n",
    "    #relevant tokens, check if it has a subject and a verb.\n",
    "    #if it does, it qualifies as a clause, else return empty list\n",
    "    #empty string\n",
    "    if check_verb_subject_in_clause(subtree_wo_clause):\n",
    "        for word in subtree_wo_clause:\n",
    "            subtree_wo_clause_string += word.text\n",
    "            subtree_wo_clause_string += \" \"\n",
    "\n",
    "    subtree_wo_clause_string = subtree_wo_clause_string.strip()            \n",
    "                \n",
    "                \n",
    "    \n",
    "        \n",
    "def get_subtree_excluding_subclause(node):\n",
    "    '''\n",
    "    Given the node, returns the subtree rooted at that node:\n",
    "    ideally to extract the subject or object subtree.\n",
    "    '''\n",
    "    black_list = [\"det\", \"punct\", \"conj\", \"cconj\"]\n",
    "    clausal_list = [\"csubj\", 'ccomp', \n",
    "                    'advcl', 'acl', 'conj',\n",
    "                    'relcl']\n",
    "    entity = []\n",
    "    entity_string = \"\"\n",
    "    for left in node.lefts:\n",
    "        \n",
    "        subtree_tokens, subtree_string, dep = get_subtree_excluding_subclause(left)\n",
    "        if dep not in clausal_list and check_verb_subject_in_clause(subtree_tokens):\n",
    "            for tok in subtree_tokens:\n",
    "                entity.append(tok)\n",
    "            \n",
    "    entity.append(node)\n",
    "    \n",
    "    for right in node.rights:\n",
    "        \n",
    "        subtree_tokens, subtree_string, dep = get_subtree_excluding_subclause(right)\n",
    "        if dep not in clausal_list and check_verb_subject_in_clause(subtree_tokens):\n",
    "            for tok in subtree_tokens:\n",
    "                entity.append(tok)\n",
    "    \n",
    "    for value in entity:\n",
    "        entity_string += value.text\n",
    "        entity_string += \" \"\n",
    "        \n",
    "    entity_string = entity_string.strip()\n",
    "    return entity, entity_string, node.dep_\n",
    "    \n",
    "def extract_clauses(sent):\n",
    "    '''\n",
    "    Given a sentence, will break the sentence into \n",
    "    different clauses\n",
    "    '''\n",
    "    doc = nlp(sent)\n",
    "    #the idea is to find one of the dep_ from the following \n",
    "    #list \n",
    "    '''\n",
    "    [ parataxis, \n",
    "      conj - conjunct,\n",
    "      ccomp - clausal complement,\n",
    "      advcl - adverbal complement,\n",
    "      relcl - relative clause modifier,\n",
    "      csubj - clausal subject\n",
    "      xcomp - open clausal complement]\n",
    "    '''\n",
    "    clause_dep_list = [\"ROOT\", \"csubj\", 'ccomp', \n",
    "                    'advcl', 'acl', 'conj',\n",
    "                   'relcl']\n",
    "    \n",
    "    clause_list = []\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.dep_ in clause_dep_list:\n",
    "            \n",
    "            subclause, _ = get_subtree_excluding_subclause(token.subtree)\n",
    "            #check if the subclause contains a verb and a subject\n",
    "            #if not then it does not qualify as a clause\n",
    "            check_verb_subject_in_clause(subclause)\n",
    "            clause_list.append(subclause)\n",
    "    \n",
    "    return clause_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence : Even with the weather being that nasty, the couple and their families decided to go ahead with the wedding as planned.  \n",
      "\n",
      "\n",
      "Its analysis :\n",
      "Even  |  advmod  |  ADV  |  with  |  ADP  |  []  |  []  |  []\n",
      "with  |  prep  |  ADP  |  decided  |  VERB  |  ['Even']  |  ['being']  |  ['Even', 'being']\n",
      "the  |  det  |  DET  |  weather  |  NOUN  |  []  |  []  |  []\n",
      "weather  |  nsubj  |  NOUN  |  being  |  AUX  |  ['the']  |  []  |  ['the']\n",
      "being  |  pcomp  |  AUX  |  with  |  ADP  |  ['weather']  |  ['nasty']  |  ['weather', 'nasty']\n",
      "that  |  advmod  |  ADV  |  nasty  |  ADJ  |  []  |  []  |  []\n",
      "nasty  |  acomp  |  ADJ  |  being  |  AUX  |  ['that']  |  []  |  ['that']\n",
      ",  |  punct  |  PUNCT  |  decided  |  VERB  |  []  |  []  |  []\n",
      "the  |  det  |  DET  |  couple  |  NOUN  |  []  |  []  |  []\n",
      "couple  |  nsubj  |  NOUN  |  decided  |  VERB  |  ['the']  |  ['and', 'families']  |  ['the', 'and', 'families']\n",
      "and  |  cc  |  CCONJ  |  couple  |  NOUN  |  []  |  []  |  []\n",
      "their  |  poss  |  DET  |  families  |  NOUN  |  []  |  []  |  []\n",
      "families  |  conj  |  NOUN  |  couple  |  NOUN  |  ['their']  |  []  |  ['their']\n",
      "decided  |  ROOT  |  VERB  |  decided  |  VERB  |  ['with', ',', 'couple']  |  ['go', '.']  |  ['with', ',', 'couple', 'go', '.']\n",
      "to  |  aux  |  PART  |  go  |  VERB  |  []  |  []  |  []\n",
      "go  |  xcomp  |  VERB  |  decided  |  VERB  |  ['to']  |  ['ahead', 'with', 'planned']  |  ['to', 'ahead', 'with', 'planned']\n",
      "ahead  |  advmod  |  ADV  |  go  |  VERB  |  []  |  []  |  []\n",
      "with  |  prep  |  ADP  |  go  |  VERB  |  []  |  ['wedding']  |  ['wedding']\n",
      "the  |  det  |  DET  |  wedding  |  NOUN  |  []  |  []  |  []\n",
      "wedding  |  pobj  |  NOUN  |  with  |  ADP  |  ['the']  |  []  |  ['the']\n",
      "as  |  mark  |  SCONJ  |  planned  |  VERB  |  []  |  []  |  []\n",
      "planned  |  advcl  |  VERB  |  go  |  VERB  |  ['as']  |  []  |  ['as']\n",
      ".  |  punct  |  PUNCT  |  decided  |  VERB  |  []  |  []  |  []\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0962881b3af7423880cb87c97e2b34f0-0\" class=\"displacy\" width=\"3725\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Even</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">weather</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">being</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">nasty,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">couple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">their</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">families</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">decided</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">go</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">ahead</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">wedding</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">planned.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,439.5 200.0,439.5 200.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-1\" stroke-width=\"2px\" d=\"M245,527.0 C245,2.0 2150.0,2.0 2150.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,529.0 L237,517.0 253,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-2\" stroke-width=\"2px\" d=\"M420,527.0 C420,439.5 550.0,439.5 550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,529.0 L412,517.0 428,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-3\" stroke-width=\"2px\" d=\"M595,527.0 C595,439.5 725.0,439.5 725.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,529.0 L587,517.0 603,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-4\" stroke-width=\"2px\" d=\"M245,527.0 C245,264.5 735.0,264.5 735.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,529.0 L743.0,517.0 727.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-5\" stroke-width=\"2px\" d=\"M945,527.0 C945,439.5 1075.0,439.5 1075.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,529.0 L937,517.0 953,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-6\" stroke-width=\"2px\" d=\"M770,527.0 C770,352.0 1080.0,352.0 1080.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1080.0,529.0 L1088.0,517.0 1072.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-7\" stroke-width=\"2px\" d=\"M1295,527.0 C1295,439.5 1425.0,439.5 1425.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,529.0 L1287,517.0 1303,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-8\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,177.0 2140.0,177.0 2140.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,529.0 L1462,517.0 1478,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-9\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,439.5 1600.0,439.5 1600.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600.0,529.0 L1608.0,517.0 1592.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-10\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,439.5 1950.0,439.5 1950.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,529.0 L1812,517.0 1828,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-11\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,264.5 1960.0,264.5 1960.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,529.0 L1968.0,517.0 1952.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-12\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,439.5 2475.0,439.5 2475.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,529.0 L2337,517.0 2353,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-13\" stroke-width=\"2px\" d=\"M2170,527.0 C2170,352.0 2480.0,352.0 2480.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2480.0,529.0 L2488.0,517.0 2472.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-14\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,439.5 2650.0,439.5 2650.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2650.0,529.0 L2658.0,517.0 2642.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-15\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,352.0 2830.0,352.0 2830.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2830.0,529.0 L2838.0,517.0 2822.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-16\" stroke-width=\"2px\" d=\"M3045,527.0 C3045,439.5 3175.0,439.5 3175.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3045,529.0 L3037,517.0 3053,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-17\" stroke-width=\"2px\" d=\"M2870,527.0 C2870,352.0 3180.0,352.0 3180.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3180.0,529.0 L3188.0,517.0 3172.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-18\" stroke-width=\"2px\" d=\"M3395,527.0 C3395,439.5 3525.0,439.5 3525.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3395,529.0 L3387,517.0 3403,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0962881b3af7423880cb87c97e2b34f0-0-19\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,89.5 3545.0,89.5 3545.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0962881b3af7423880cb87c97e2b34f0-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3545.0,529.0 L3553.0,517.0 3537.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/May/2020 13:12:44] \"GET / HTTP/1.1\" 200 17617\n",
      "127.0.0.1 - - [29/May/2020 13:12:44] \"GET /favicon.ico HTTP/1.1\" 200 17617\n"
     ]
    }
   ],
   "source": [
    "sentence = en_data[88120]\n",
    "sentence1 = \"the city of the loir-et-cher is part of the greater mumbai\"\n",
    "sentence2 = 'Even with the weather being that nasty, the couple and their families decided to go ahead \\\n",
    "with the wedding as planned.'\n",
    "sentence3 = 'My little daughter loves to play with her dolls.'\n",
    "sentence4 = 'Because she loves her students, Mrs Stevens will be sad on the last day of school.'\n",
    "compound_sentence = 'I like road bikes, and he likes mountain bikes.'\n",
    "compound_sentence = 'She ran with the dogs, I swam with the fishes, and they biked to the mountains.'\n",
    "sentence5 = 'My mother suggested that I should consult a doctor'\n",
    "complex_sent = 'John retired when he turned 65'\n",
    "complex_sent2 = 'Whether you agree with me or not makes little \\\n",
    "difference to our inverstors, who by the way, are the ones most \\\n",
    "affected by whatever mistake we make.'\n",
    "complex_sent3 = 'Whoever thought of the idea is a genius.'\n",
    "complex_compound1 = \"Bill voted against the measure \\\n",
    "because he felt that it wasn't strong enough, but he also offered \\\n",
    "to continue discussions, which we will do next week.\" \n",
    "current = sentence2\n",
    "doc = nlp(current)\n",
    "print(\"The sentence :\", current,\" \\n\\n\")\n",
    "\n",
    "print(\"Its analysis :\")\n",
    "for token in doc:\n",
    "    print(token.text,\" | \",  token.dep_,\" | \", token.pos_, \" | \", token.head.text,\" | \",  token.head.pos_,\" | \", \n",
    "           [left.text for left in token.lefts], \" | \",\n",
    "           [right.text for right in token.rights], \" | \",\n",
    "           [child.text for child in token.children])\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "'''\n",
    "black_list = [\"det\", \"punct\", \"conj\", \"cconj\"]\n",
    "clausal_list = [\"csubj\", 'ccomp', \n",
    "                'advcl', 'acl', 'conj',\n",
    "                'relcl']\n",
    "\n",
    "print(extract_clauses(current))\n",
    "\n",
    "extracted_clauses = extract_clauses(current)\n",
    "for clause in extracted_clauses:\n",
    "    print(\"Clause :\", clause, check_verb_subject_in_clause(clause))\n",
    "\n",
    "print(\"Printing the extracted clauses :\", extracted_clauses)\n",
    "print(\"\\n\\n\")\n",
    "entities_other = get_entities(current)\n",
    "relation_other = get_relation(current)\n",
    "print(\"\\nentity and relations from the blog:\\nSubject : {} | Object : {} | Relation : {}\\n\\n\".format(entities_other[0], \n",
    "                                                                               entities_other[1],\n",
    "                                                                               relation_other))\n",
    "\n",
    "entity_list = extract_entity_relation_tuples(current)\n",
    "for entity in entity_list:\n",
    "    subj, obj = entity[0]\n",
    "    rel = entity[1]\n",
    "    print(\"\\nentity and relations from my code:\\nSubject : {} | Object : {} | Relation : {}\\n\\n\".format(subj, \n",
    "                                                                              obj, rel))\n",
    "\n",
    "print(extract_entities_from_clause(current))\n",
    "print(extract_relation_from_clause(current))\n",
    "'''   \n",
    "displacy.serve(doc, style='dep')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence : Her story might be embarrasing for some of her friends. \n",
      "The extraction : ('Her story', 'some') \n",
      "The other extraction : ['story', 'friends'] \n",
      "The relation : |be embarrasing\n"
     ]
    }
   ],
   "source": [
    "print(\"The sentence : {} \\nThe extraction : {} \\nThe other extraction : {} \\n\\\n",
    "The relation : |{}\".format(current, entities, entities_other, relation_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token : John | The subtree : \n",
      "\n",
      "<generator object at 0x7f5beb634558>\n",
      "The token : retired | The subtree : \n",
      "\n",
      "<generator object at 0x7f5beb634678>\n",
      "<generator object at 0x7f5beb634558>\n",
      "<generator object at 0x7f5beb634798>\n",
      "<generator object at 0x7f5beb634798>\n",
      "<generator object at 0x7f5beb634678>\n",
      "<generator object at 0x7f5beb634798>\n",
      "The token : when | The subtree : \n",
      "\n",
      "<generator object at 0x7f5beb634558>\n",
      "The token : he | The subtree : \n",
      "\n",
      "<generator object at 0x7f5beb634558>\n",
      "The token : turned | The subtree : \n",
      "\n",
      "<generator object at 0x7f5beb634678>\n",
      "<generator object at 0x7f5beb634678>\n",
      "<generator object at 0x7f5beb634558>\n",
      "<generator object at 0x7f5beb634678>\n",
      "The token : 65 | The subtree : \n",
      "\n",
      "<generator object at 0x7f5beb634558>\n"
     ]
    }
   ],
   "source": [
    "sent = complex_sent\n",
    "doc = nlp(sent)\n",
    "\n",
    "for token in doc:\n",
    "    print(\"The token : {} | The subtree : \\n\".format(token))\n",
    "    for sub in token.subtree:\n",
    "        print(sub.lefts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "John retired when he turned 65"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyRL3",
   "language": "python",
   "name": "pyrl3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
